name: Run PM001 Scraper

on:
  schedule:
    - cron: '0 2 * * *'  # 每天UTC时间2点运行（相当于北京时间10点）
  workflow_dispatch:      # 允许手动触发

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v2
      with:
        fetch-depth: 0  # 获取完整的历史记录，以便正确进行git操作
    
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f requirements.txt ]; then pip install -r requirements.txt; else pip install requests beautifulsoup4; fi
        
    - name: Run scraper
      run: |
        python 测试.py
        
    - name: Upload results as artifact
      uses: actions/upload-artifact@v2
      with:
        name: scraped-data-${{ github.run_number }}
        path: pm001_recent_posts.tsv
        retention-days: 90  # 保留90天
        
    - name: Commit and push results
      run: |
        git config --global user.name 'GitHub Actions Bot'
        git config --global user.email 'actions@github.com'
        git add pm001_recent_posts.tsv || true
        git diff --quiet && git diff --staged --quiet || git commit -m "自动更新爬虫数据 $(date +'%Y-%m-%d')"
        git push || echo "No changes to push"
